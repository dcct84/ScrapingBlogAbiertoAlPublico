Recomendaciones para analizar datos basados en encuestas Por: Eladio Montero de Grupo Inco En las noticias vemos como algún tema es discutido y respaldado por encuestas, estudios y estadísticas. Instituciones de investigación, organizaciones gubernamentales y empresas privadas utilizan estos instrumentos exhaustivamente para apoyar su toma de decisiones. Ahora bien, acontecimientos ocurridos este año, como las elecciones de los Estados Unidos, el Brexit del Reino Unido, y el No en Colombia, en los cuales recursos estadísticos predijeron algo distinto al resultado final, nos dejan una buena oportunidad para reflexionar sobre el análisis de datos. Se pronosticó que Inglaterra votaba por el Remain, o quedarse en la Unión Europea, que Colombia aprobaba el tratado de paz con las FARC, y que Hillary Clinton ocuparía la silla en la Casa Blanca. Como todos sabemos, ninguno de estos tres escenarios sucedió como se esperaba. Los tres resultados fueron sorpresivos, de gran escala y posiblemente afectarán el panorama mundial en los próximos años. A continuación presento algunas recomendaciones sobre el uso de datos de encuestas:   1  Analice la muestra que representan los datos En muchas ocasiones, analizar una situación de manera cuantitativa conlleva a tomar todo tipo de decisiones con los datos que se van a utilizar. Ahora bien, no es posible recolectar la opinión de toda la población o considerar todas las posibles variables que afectarán una decisión, tampoco se pueden recrear todos los posibles escenarios en los cuales se desarrollará el sujeto del estudio. Se deben tomar riesgos, se asumen supuestos y se consideran márgenes de error. Y se supone que funciona así, por practicidad y escalabilidad del estudio. Es importante además, tomar en cuenta el tamaño de la muestra y su grado de inferencia (la capacidad de la muestra de explicar el comportamiento de toda la población), ni muy pequeña incapaz de generalizar, ni muy grande haciendo que la recolección de datos se vuelva impráctica. Más de este tema en esta guía sobre muestreo publicada por el Instituto Nacional de Estadística y Geografía de México.   2  Ponga a prueba la representatividad de los datos Expertos afirman que una de las causas principales de por qué las encuestas fallaron en detectar que el nuevo presidente electo sería Trump, o que Leave ganaría en Inglaterra, es porque la muestra posiblemente no fue representativa, en otras palabras, no se tomaron en cuenta todos los tipos de votantes y sus motivos. En un problema de clasificación, es decir, que el resultado puede ser determinado entre una serie de opciones (positivo/negativo, sí/no, republicano/demócrata), es importante que la muestra cubra la mayor cantidad de escenarios, para evitar caer en lo que se denomina error de muestreo.   3 Ponga a prueba la veracidad de las respuestas FiveThirtyEight (538), blog del famoso estadístico Nate Silver, quien logró pronosticar con mucha precisión las elecciones de Estados Unidos del 2008 y 2012 con su modelo innovador, postuló a Clinton como ganadora de las últimas elecciones con 80% de probabilidades de llevarse la presidencia. 538 argumenta que es muy difícil decir con claridad a tan pocos días qué falló en un modelo estadístico tan complejo, pero especulan que muchas personas no respondieron las encuestas con su verdadera intención de voto, o no respondieron del todo. Esto es conocido como sesgo de no respuesta. Por otro lado, es incorrecto apelar a una figura y lo que representa para defender o contradecir una posición ya que esto tiene poco que ver con la variable a predecir (intención de voto). Esto se conoce como falacia ad-hominem. Cuando se realizan estudios sobre temas sensibles, se debe recordar que no todos están dispuestos a dar a una opinión abierta sobre el tema y posibles sorpresas se pueden esconder entre las filas de datos.   4  Cuestione la metodología y su interpretación Más allá de lo estadístico, es importante considerar que aquello que funcionó anteriormente no necesariamente va a funcionar en el futuro, así como los pronósticos de FiveThirtyEight sirvieron en las elecciones de 2008 y 2012, nuevas variables entraron en juego y claramente se vio reflejado en los resultados. Según Carl Sagan, cada vez que algo establecido se cuestiona, se hace ciencia. Muchos analistas además apuestan a buscar evidencia para afirmar la posición que defienden, o el resultado que esperan, obviando muchas veces señales que contradicen su posición (también conocido como sesgo de confirmación). Todo esto con datos que en la teoría y la práctica están correctos, pero interpretados de manera incorrecta.   5 Aprenda de los errores Ahora bien, la lección más importante que los analistas de datos deben aprender de estos acontecimientos, es que los instrumentos estadísticos son propensos a errores y el mejor camino a tomar es asimilarlos y mejorar los estudios con estas nuevas enseñanzas. Por supuesto, en este momento parece muy lógico para algunos que se pasaron cosas por alto, incluso es muy probable que estos estadísticos de renombre mundial tomaron en cuenta los puntos anteriores, por lo que nuevamente, tomará algún tiempo saber exactamente qué sucedió. Después de todo, añadir variables a una muestra, en teoría, mejora la precisión del modelo. De la misma manera, el analista puede añadir nuevas consideraciones a sus estudios y mejorar la veracidad de los resultados.   Eladio Montero Analista de datos, consultor de Grupo Inco, y autodidacta. Egresado de Informática Empresarial en la Universidad de Costa Rica.      